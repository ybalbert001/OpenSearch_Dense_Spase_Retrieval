{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c197463-fb38-4507-afc1-b6bf6c093b29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opensearch-py\n",
      "  Downloading opensearch_py-2.4.2-py2.py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: urllib3>=1.26.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (1.26.18)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (2.31.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from opensearch-py) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py) (3.4)\n",
      "Downloading opensearch_py-2.4.2-py2.py3-none-any.whl (258 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.6/258.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opensearch-py\n",
      "Successfully installed opensearch-py-2.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install -q datasets\n",
    "!pip install opensearch-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d406d8c-5680-47fa-bbc3-ad0e34da41d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdeb0ff141d24bbba7147213cdd1f8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4196045a60f140199c8c70d53b2597a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e8cab51ca240b6800bfea4f0486aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/8.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "115300b060b34d858fb4a420581357f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1da1064dfd40708612513f644b10c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/9.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1cd7d70fbc84056abdbd908f2d052ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/801k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb351fe4c36f420e8e7589e91eaa48c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5631e175e54fd185855fd51492954e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/130319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faea48791e164761b7f39ac05bd2a18c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11873 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 130319\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
      "        num_rows: 11873\n",
      "    })\n",
      "})\n",
      "{'id': '56be85543aeaaa14008c9063', 'title': 'Beyoncé', 'context': 'Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ bee-YON-say) (born September 4, 1981) is an American singer, songwriter, record producer and actress. Born and raised in Houston, Texas, she performed in various singing and dancing competitions as a child, and rose to fame in the late 1990s as lead singer of R&B girl-group Destiny\\'s Child. Managed by her father, Mathew Knowles, the group became one of the world\\'s best-selling girl groups of all time. Their hiatus saw the release of Beyoncé\\'s debut album, Dangerously in Love (2003), which established her as a solo artist worldwide, earned five Grammy Awards and featured the Billboard Hot 100 number-one singles \"Crazy in Love\" and \"Baby Boy\".', 'question': 'When did Beyonce start becoming popular?', 'answers': {'text': ['in the late 1990s'], 'answer_start': [269]}}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 选择要下载的数据集名称，可以在 Hugging Face 数据集网站上查找\n",
    "dataset_name = \"squad_v2\"\n",
    "\n",
    "# 下载数据集\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# 打印数据集信息\n",
    "print(dataset)\n",
    "\n",
    "# 访问数据集中的示例\n",
    "sample = dataset[\"train\"][0]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37aaf68c-1959-4348-88b9-af0dca2807f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import requests\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth, helpers\n",
    "\n",
    "service = 'es'\n",
    "session = boto3.Session()\n",
    "credentials = session.get_credentials()\n",
    "region = session.region_name\n",
    "auth = AWSV4SignerAuth(credentials, region)\n",
    "aos_endpoint='vpc-domain66ac69e0-ijsmtgwnje5s-oa63og27tmacx2fstb5hpstta4.us-west-2.es.amazonaws.com'\n",
    "\n",
    "client = OpenSearch(\n",
    "    hosts = [{'host': aos_endpoint, 'port': 443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    timeout = 60, # 默认超时时间是10 秒，\n",
    "    max_retries=5, # 重试次数\n",
    "    retry_on_timeout=True\n",
    ")\n",
    "\n",
    "index_name = \"your-index-name\"\n",
    "index_mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"field1\": {\"type\": \"text\"},\n",
    "            \"field2\": {\"type\": \"integer\"},\n",
    "            # 添加其他字段和其数据类型\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# 创建索引\n",
    "response = client.indices.delete(index=index_name)\n",
    "# response = client.indices.create(index=index_name, body=index_mapping)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ed6c74-428b-4ccd-ba4a-eadfa82b39a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "request_body = {\n",
    "  \"parameters\": {\n",
    "    \"texts\": [\"Hello word\", \"Hi Altman\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "# Execute the _predict request\n",
    "response = client.transport.perform_request(\n",
    "    method=\"POST\",\n",
    "    url=f\"/_plugins/_ml/models/4EtIC4wB0S9ucTLoWVtt/_predict\",\n",
    "    body=json.dumps(request_body)\n",
    ")\n",
    "\n",
    "request_body = {\n",
    "  \"description\": \"neural sparse encoding pipeline\",\n",
    "  \"processors\" : [\n",
    "    {\n",
    "      \"sparse_encoding\": {\n",
    "        \"model_id\": \"<nerual_sparse_model_id>\",\n",
    "        \"field_map\": {\n",
    "           \"content\": \"sparse_embedding\"\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"text_embedding\": {\n",
    "        \"model_id\": \"<cohere_ingest_model_id>\",\n",
    "        \"field_map\": {\n",
    "          \"doc\": \"embedding\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "response = client.transport.perform_request(\n",
    "    method=\"PUT\",\n",
    "    url=f\"/_ingest/pipeline/dense-sparse-pipeline\",\n",
    "    body=json.dumps(request_body)\n",
    ")\n",
    "\n",
    "PUT /_ingest/pipeline/dense-sparse-pipeline\n",
    "{\n",
    "  \"description\": \"neural sparse encoding pipeline\",\n",
    "  \"processors\" : [\n",
    "    {\n",
    "      \"sparse_encoding\": {\n",
    "        \"model_id\": \"<nerual_sparse_model_id>\",\n",
    "        \"field_map\": {\n",
    "           \"content\": \"sparse_embedding\"\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"text_embedding\": {\n",
    "        \"model_id\": \"<cohere_ingest_model_id>\",\n",
    "        \"field_map\": {\n",
    "          \"doc\": \"embedding\"\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\n",
    "GET /_plugins/_ml/models/\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "131e6447-f2de-40e4-a5a1-94ea7bb18066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AuthenticationException",
     "evalue": "AuthenticationException(401, '{\"Message\":\"Your request: \\'/_ml/trained_models\\' is not allowed.\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAuthenticationException\u001b[0m                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/_ml/trained_models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/transport.py:448\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    446\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 448\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# connection didn't fail, confirm its live status\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnection_pool\u001b[38;5;241m.\u001b[39mmark_live(connection)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/transport.py:409\u001b[0m, in \u001b[0;36mTransport.perform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    406\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_connection()\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     status, headers_response, data \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    419\u001b[0m     \u001b[38;5;66;03m# Lowercase all the header names for consistency in accessing them.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m     headers_response \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    421\u001b[0m         header\u001b[38;5;241m.\u001b[39mlower(): value \u001b[38;5;28;01mfor\u001b[39;00m header, value \u001b[38;5;129;01min\u001b[39;00m headers_response\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    422\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/http_requests.py:232\u001b[0m, in \u001b[0;36mRequestsHttpConnection.perform_request\u001b[0;34m(self, method, url, params, body, timeout, allow_redirects, ignore, headers)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m)\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ignore\n\u001b[1;32m    222\u001b[0m ):\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_request_fail(\n\u001b[1;32m    224\u001b[0m         method,\n\u001b[1;32m    225\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m         raw_data,\n\u001b[1;32m    231\u001b[0m     )\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_error\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mContent-Type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_request_success(\n\u001b[1;32m    239\u001b[0m     method,\n\u001b[1;32m    240\u001b[0m     url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     duration,\n\u001b[1;32m    246\u001b[0m )\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m.\u001b[39mheaders, raw_data\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/opensearchpy/connection/base.py:316\u001b[0m, in \u001b[0;36mConnection._raise_error\u001b[0;34m(self, status_code, raw_data, content_type)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    314\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUndecodable raw error response from server: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, err)\n\u001b[0;32m--> 316\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HTTP_EXCEPTIONS\u001b[38;5;241m.\u001b[39mget(status_code, TransportError)(\n\u001b[1;32m    317\u001b[0m     status_code, error_message, additional_info\n\u001b[1;32m    318\u001b[0m )\n",
      "\u001b[0;31mAuthenticationException\u001b[0m: AuthenticationException(401, '{\"Message\":\"Your request: \\'/_ml/trained_models\\' is not allowed.\"}')"
     ]
    }
   ],
   "source": [
    "response = client.transport.perform_request(\n",
    "    method=\"GET\",\n",
    "    url=\"/_ml/trained_models\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fcb9d59-43c4-4752-a038-6ab0bda1dc17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on OpenSearch in module opensearchpy.client object:\n",
      "\n",
      "class OpenSearch(opensearchpy.client.client.Client)\n",
      " |  OpenSearch(hosts: Any = None, transport_class: Type[opensearchpy.transport.Transport] = <class 'opensearchpy.transport.Transport'>, **kwargs: Any) -> None\n",
      " |  \n",
      " |  OpenSearch client. Provides a straightforward mapping from\n",
      " |  Python to OpenSearch REST endpoints.\n",
      " |  \n",
      " |  The instance has attributes ``cat``, ``cluster``, ``indices``, ``ingest``,\n",
      " |  ``nodes``, ``snapshot`` and ``tasks`` that provide access to instances of\n",
      " |  :class:`~opensearchpy.client.CatClient`,\n",
      " |  :class:`~opensearchpy.client.ClusterClient`,\n",
      " |  :class:`~opensearchpy.client.IndicesClient`,\n",
      " |  :class:`~opensearchpy.client.IngestClient`,\n",
      " |  :class:`~opensearchpy.client.NodesClient`,\n",
      " |  :class:`~opensearchpy.client.SnapshotClient` and\n",
      " |  :class:`~opensearchpy.client.TasksClient` respectively. This is the\n",
      " |  preferred (and only supported) way to get access to those classes and their\n",
      " |  methods.\n",
      " |  \n",
      " |  You can specify your own connection class which should be used by providing\n",
      " |  the ``connection_class`` parameter::\n",
      " |  \n",
      " |      # create connection to localhost using the ThriftConnection\n",
      " |      client = OpenSearch(connection_class=ThriftConnection)\n",
      " |  \n",
      " |  If you want to turn on sniffing you have several options (described\n",
      " |  in :class:`~opensearchpy.Transport`)::\n",
      " |  \n",
      " |      # create connection that will automatically inspect the cluster to get\n",
      " |      # the list of active nodes. Start with nodes running on\n",
      " |      # 'opensearchnode1' and 'opensearchnode2'\n",
      " |      client = OpenSearch(\n",
      " |          ['opensearchnode1', 'opensearchnode2'],\n",
      " |          # sniff before doing anything\n",
      " |          sniff_on_start=True,\n",
      " |          # refresh nodes after a node fails to respond\n",
      " |          sniff_on_connection_fail=True,\n",
      " |          # and also every 60 seconds\n",
      " |          sniffer_timeout=60\n",
      " |      )\n",
      " |  \n",
      " |  Different hosts can have different parameters, use a dictionary per node to\n",
      " |  specify those::\n",
      " |  \n",
      " |      # connect to localhost directly and another node using SSL on port 443\n",
      " |      # and an url_prefix. Note that ``port`` needs to be an int.\n",
      " |      client = OpenSearch([\n",
      " |          {'host': 'localhost'},\n",
      " |          {'host': 'othernode', 'port': 443, 'url_prefix': 'opensearch', 'use_ssl': True},\n",
      " |      ])\n",
      " |  \n",
      " |  If using SSL, there are several parameters that control how we deal with\n",
      " |  certificates (see :class:`~opensearchpy.Urllib3HttpConnection` for\n",
      " |  detailed description of the options)::\n",
      " |  \n",
      " |      client = OpenSearch(\n",
      " |          ['localhost:443', 'other_host:443'],\n",
      " |          # turn on SSL\n",
      " |          use_ssl=True,\n",
      " |          # make sure we verify SSL certificates\n",
      " |          verify_certs=True,\n",
      " |          # provide a path to CA certs on disk\n",
      " |          ca_certs='/path/to/CA_certs'\n",
      " |      )\n",
      " |  \n",
      " |  If using SSL, but don't verify the certs, a warning message is showed\n",
      " |  optionally (see :class:`~opensearchpy.Urllib3HttpConnection` for\n",
      " |  detailed description of the options)::\n",
      " |  \n",
      " |      client = OpenSearch(\n",
      " |          ['localhost:443', 'other_host:443'],\n",
      " |          # turn on SSL\n",
      " |          use_ssl=True,\n",
      " |          # no verify SSL certificates\n",
      " |          verify_certs=False,\n",
      " |          # don't show warnings about ssl certs verification\n",
      " |          ssl_show_warn=False\n",
      " |      )\n",
      " |  \n",
      " |  SSL client authentication is supported\n",
      " |  (see :class:`~opensearchpy.Urllib3HttpConnection` for\n",
      " |  detailed description of the options)::\n",
      " |  \n",
      " |      client = OpenSearch(\n",
      " |          ['localhost:443', 'other_host:443'],\n",
      " |          # turn on SSL\n",
      " |          use_ssl=True,\n",
      " |          # make sure we verify SSL certificates\n",
      " |          verify_certs=True,\n",
      " |          # provide a path to CA certs on disk\n",
      " |          ca_certs='/path/to/CA_certs',\n",
      " |          # PEM formatted SSL client certificate\n",
      " |          client_cert='/path/to/clientcert.pem',\n",
      " |          # PEM formatted SSL client key\n",
      " |          client_key='/path/to/clientkey.pem'\n",
      " |      )\n",
      " |  \n",
      " |  Alternatively you can use RFC-1738 formatted URLs, as long as they are not\n",
      " |  in conflict with other options::\n",
      " |  \n",
      " |      client = OpenSearch(\n",
      " |          [\n",
      " |              'http://user:secret@localhost:9200/',\n",
      " |              'https://user:secret@other_host:443/production'\n",
      " |          ],\n",
      " |          verify_certs=True\n",
      " |      )\n",
      " |  \n",
      " |  By default, `JSONSerializer\n",
      " |  <https://github.com/opensearch-project/opensearch-py/blob/master/opensearch/serializer.py#L24>`_\n",
      " |  is used to encode all outgoing requests.\n",
      " |  However, you can implement your own custom serializer::\n",
      " |  \n",
      " |      from opensearchpy.serializer import JSONSerializer\n",
      " |  \n",
      " |      class SetEncoder(JSONSerializer):\n",
      " |          def default(self, obj):\n",
      " |              if isinstance(obj, set):\n",
      " |                  return list(obj)\n",
      " |              if isinstance(obj, Something):\n",
      " |                  return 'CustomSomethingRepresentation'\n",
      " |              return JSONSerializer.default(self, obj)\n",
      " |  \n",
      " |      client = OpenSearch(serializer=SetEncoder())\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      OpenSearch\n",
      " |      opensearchpy.client.client.Client\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self) -> Any\n",
      " |  \n",
      " |  __exit__(self, *_: Any) -> None\n",
      " |  \n",
      " |  __init__(self, hosts: Any = None, transport_class: Type[opensearchpy.transport.Transport] = <class 'opensearchpy.transport.Transport'>, **kwargs: Any) -> None\n",
      " |      :arg hosts: list of nodes, or a single node, we should connect to.\n",
      " |          Node should be a dictionary ({\"host\": \"localhost\", \"port\": 9200}),\n",
      " |          the entire dictionary will be passed to the :class:`~opensearchpy.Connection`\n",
      " |          class as kwargs, or a string in the format of ``host[:port]`` which will be\n",
      " |          translated to a dictionary automatically.  If no value is given the\n",
      " |          :class:`~opensearchpy.Connection` class defaults will be used.\n",
      " |      \n",
      " |      :arg transport_class: :class:`~opensearchpy.Transport` subclass to use.\n",
      " |      \n",
      " |      :arg kwargs: any additional arguments will be passed on to the\n",
      " |          :class:`~opensearchpy.Transport` class and, subsequently, to the\n",
      " |          :class:`~opensearchpy.Connection` instances.\n",
      " |  \n",
      " |  __repr__(self) -> Any\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  bulk(self, body: Any, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to perform multiple index/update/delete operations in a single request.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The operation definition and data (action-data\n",
      " |          pairs), separated by newlines\n",
      " |      :arg index: Default index for items which don't provide one.\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or default list of fields to return, can be overridden on each sub-\n",
      " |          request.\n",
      " |      :arg _source_excludes: Default list of fields to exclude from\n",
      " |          the returned _source field, can be overridden on each sub-request.\n",
      " |      :arg _source_includes: Default list of fields to extract and\n",
      " |          return from the _source field, can be overridden on each sub-request.\n",
      " |      :arg pipeline: The pipeline id to preprocess incoming documents\n",
      " |          with.\n",
      " |      :arg refresh: If `true` then refresh the affected shards to make\n",
      " |          this operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default) then\n",
      " |          do nothing with refreshes. Valid choices are true, false, wait_for.\n",
      " |      :arg require_alias: Sets require_alias for all incoming\n",
      " |          documents. Default is false.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg timeout: Operation timeout.\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies\n",
      " |          that must be active before proceeding with the operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the total\n",
      " |          number of copies for the shard (number of replicas + 1). Default is 1.\n",
      " |  \n",
      " |  clear_scroll(self, body: Any = None, scroll_id: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Explicitly clears the search context for a scroll.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: Comma-separated list of scroll IDs to clear if none\n",
      " |          was specified via the scroll_id parameter\n",
      " |      :arg scroll_id: Comma-separated list of scroll IDs to clear.\n",
      " |  \n",
      " |  close(self) -> None\n",
      " |      Closes the Transport and all internal connections\n",
      " |  \n",
      " |  count(self, body: Any = None, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns number of documents matching a query.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: Query to restrict the results specified with the\n",
      " |          Query DSL (optional)\n",
      " |      :arg index: Comma-separated list of indices to restrict the\n",
      " |          results.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified).\n",
      " |      :arg analyze_wildcard: Specify whether wildcard and prefix\n",
      " |          queries should be analyzed. Default is false.\n",
      " |      :arg analyzer: The analyzer to use for the query string.\n",
      " |      :arg default_operator: The default operator for query string\n",
      " |          query (AND or OR). Valid choices are AND, OR.\n",
      " |      :arg df: The field to use as default where no field prefix is\n",
      " |          given in the query string.\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg ignore_throttled: Whether specified concrete, expanded or\n",
      " |          aliased indices should be ignored when throttled.\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed).\n",
      " |      :arg lenient: Specify whether format-based query failures (such\n",
      " |          as providing text to a numeric field) should be ignored.\n",
      " |      :arg min_score: Include only documents with a specific `_score`\n",
      " |          value in the result.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg q: Query in the Lucene query string syntax.\n",
      " |      :arg routing: Comma-separated list of specific routing values.\n",
      " |      :arg terminate_after: The maximum number of documents to collect\n",
      " |          for each shard, upon reaching which the query execution will terminate\n",
      " |          early.\n",
      " |  \n",
      " |  create(self, index: Any, id: Any, body: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Creates a new document in the index.  Returns a 409 response when a document\n",
      " |      with a same ID already exists in the index.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg id: Document ID.\n",
      " |      :arg body: The document\n",
      " |      :arg pipeline: The pipeline id to preprocess incoming documents\n",
      " |          with.\n",
      " |      :arg refresh: If `true` then refresh the affected shards to make\n",
      " |          this operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default) then\n",
      " |          do nothing with refreshes. Valid choices are true, false, wait_for.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg timeout: Operation timeout.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies\n",
      " |          that must be active before proceeding with the operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the total\n",
      " |          number of copies for the shard (number of replicas + 1). Default is 1.\n",
      " |  \n",
      " |  create_pit(self, index: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Creates point in time context.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Comma-separated list of indices; use `_all` or empty\n",
      " |          string to perform the operation on all indices.\n",
      " |      :arg allow_partial_pit_creation: Allow if point in time can be\n",
      " |          created with partial failures.\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg keep_alive: Specify the keep alive for point in time.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg routing: Comma-separated list of specific routing values.\n",
      " |  \n",
      " |  create_point_in_time(self: Any, index: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Create a point in time that can be used in subsequent searches\n",
      " |      \n",
      " |      \n",
      " |      :arg index: A comma-separated list of index names to open point\n",
      " |          in time; use `_all` or empty string to perform the operation on all\n",
      " |          indices\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both.  Valid choices: open,\n",
      " |          closed, hidden, none, all  Default: open\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed)\n",
      " |      :arg keep_alive: Specific the time to live for the point in time\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on (default: random)\n",
      " |      :arg routing: Specific routing value\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          This API will be removed in a future version.\n",
      " |          Use 'create_pit' API instead.\n",
      " |  \n",
      " |  delete(self, index: Any, id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Removes a document from the index.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg id: Document ID.\n",
      " |      :arg if_primary_term: only perform the operation if the last\n",
      " |          operation that has changed the document has the specified primary term.\n",
      " |      :arg if_seq_no: only perform the operation if the last operation\n",
      " |          that has changed the document has the specified sequence number.\n",
      " |      :arg refresh: If `true` then refresh the affected shards to make\n",
      " |          this operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default) then\n",
      " |          do nothing with refreshes. Valid choices are true, false, wait_for.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg timeout: Operation timeout.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies\n",
      " |          that must be active before proceeding with the operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the total\n",
      " |          number of copies for the shard (number of replicas + 1). Default is 1.\n",
      " |  \n",
      " |  delete_all_pits(self, params: Any = None, headers: Any = None) -> Any\n",
      " |      Deletes all active point in time searches.\n",
      " |  \n",
      " |  delete_by_query(self, index: Any, body: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Deletes documents matching the provided query.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Comma-separated list of indices; use `_all` or empty\n",
      " |          string to perform the operation on all indices.\n",
      " |      :arg body: The search definition using the Query DSL\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified).\n",
      " |      :arg analyze_wildcard: Specify whether wildcard and prefix\n",
      " |          queries should be analyzed. Default is false.\n",
      " |      :arg analyzer: The analyzer to use for the query string.\n",
      " |      :arg conflicts: What to do when the operation encounters version\n",
      " |          conflicts?. Valid choices are abort, proceed.\n",
      " |      :arg default_operator: The default operator for query string\n",
      " |          query (AND or OR). Valid choices are AND, OR.\n",
      " |      :arg df: The field to use as default where no field prefix is\n",
      " |          given in the query string.\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg from_: Starting offset. Default is 0.\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed).\n",
      " |      :arg lenient: Specify whether format-based query failures (such\n",
      " |          as providing text to a numeric field) should be ignored.\n",
      " |      :arg max_docs: Maximum number of documents to process (default:\n",
      " |          all documents).\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg q: Query in the Lucene query string syntax.\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation.\n",
      " |      :arg request_cache: Specify if request cache should be used for\n",
      " |          this request or not, defaults to index level setting.\n",
      " |      :arg requests_per_second: The throttle for this request in sub-\n",
      " |          requests per second. -1 means no throttle. Default is 0.\n",
      " |      :arg routing: Comma-separated list of specific routing values.\n",
      " |      :arg scroll: Specify how long a consistent view of the index\n",
      " |          should be maintained for scrolled search.\n",
      " |      :arg scroll_size: Size on the scroll request powering the\n",
      " |          operation. Default is 100.\n",
      " |      :arg search_timeout: Explicit timeout for each search request.\n",
      " |          Defaults to no timeout.\n",
      " |      :arg search_type: Search operation type. Valid choices are\n",
      " |          query_then_fetch, dfs_query_then_fetch.\n",
      " |      :arg size: Deprecated, please use `max_docs` instead.\n",
      " |      :arg slices: The number of slices this task should be divided\n",
      " |          into. Defaults to 1, meaning the task isn't sliced into subtasks. Can be\n",
      " |          set to `auto`. Default is 1.\n",
      " |      :arg sort: Comma-separated list of <field>:<direction> pairs.\n",
      " |      :arg stats: Specific 'tag' of the request for logging and\n",
      " |          statistical purposes.\n",
      " |      :arg terminate_after: The maximum number of documents to collect\n",
      " |          for each shard, upon reaching which the query execution will terminate\n",
      " |          early.\n",
      " |      :arg timeout: Time each individual bulk request should wait for\n",
      " |          shards that are unavailable. Default is 1m.\n",
      " |      :arg version: Whether to return document version as part of a\n",
      " |          hit.\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies\n",
      " |          that must be active before proceeding with the operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the total\n",
      " |          number of copies for the shard (number of replicas + 1). Default is 1.\n",
      " |      :arg wait_for_completion: Should this request wait until the\n",
      " |          operation has completed before returning. Default is True.\n",
      " |  \n",
      " |  delete_by_query_rethrottle(self, task_id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Changes the number of requests per second for a particular Delete By Query\n",
      " |      operation.\n",
      " |      \n",
      " |      \n",
      " |      :arg task_id: The task id to rethrottle.\n",
      " |      :arg requests_per_second: The throttle for this request in sub-\n",
      " |          requests per second. -1 means no throttle.\n",
      " |  \n",
      " |  delete_pit(self, body: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Deletes one or more point in time searches based on the IDs passed.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The point-in-time ids to be deleted\n",
      " |  \n",
      " |  delete_point_in_time(self: Any, body: Any = None, all: bool = False, params: Any = None, headers: Any = None) -> Any\n",
      " |      Delete a point in time\n",
      " |      \n",
      " |      \n",
      " |      :arg body: a point-in-time id to delete\n",
      " |      :arg all: set it to `True` to delete all alive point in time.\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          This API will be removed in a future version.\n",
      " |          Use 'delete_all_pits' or 'delete_pit' API instead.\n",
      " |  \n",
      " |  delete_script(self, id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Deletes a script.\n",
      " |      \n",
      " |      \n",
      " |      :arg id: Script ID.\n",
      " |      :arg cluster_manager_timeout: Operation timeout for connection\n",
      " |          to cluster-manager node.\n",
      " |      :arg master_timeout (Deprecated: To promote inclusive language,\n",
      " |          use 'cluster_manager_timeout' instead.): Operation timeout for\n",
      " |          connection to master node.\n",
      " |      :arg timeout: Operation timeout.\n",
      " |  \n",
      " |  exists(self, index: Any, id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns information about whether a document exists in an index.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg id: Document ID.\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg realtime: Specify whether to perform the operation in\n",
      " |          realtime or search mode.\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg stored_fields: Comma-separated list of stored fields to\n",
      " |          return.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |  \n",
      " |  exists_source(self, index: Any, id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns information about whether a document source exists in an index.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg id: Document ID.\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg realtime: Specify whether to perform the operation in\n",
      " |          realtime or search mode.\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |  \n",
      " |  explain(self, index: Any, id: Any, body: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns information about why a specific matches (or doesn't match) a query.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg id: Document ID.\n",
      " |      :arg body: The query definition using the Query DSL\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg analyze_wildcard: Specify whether wildcards and prefix\n",
      " |          queries in the query string query should be analyzed. Default is false.\n",
      " |      :arg analyzer: The analyzer to use for the query string.\n",
      " |      :arg default_operator: The default operator for query string\n",
      " |          query (AND or OR). Valid choices are AND, OR.\n",
      " |      :arg df: The default field for query string query. Default is\n",
      " |          _all.\n",
      " |      :arg lenient: Specify whether format-based query failures (such\n",
      " |          as providing text to a numeric field) should be ignored.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg q: Query in the Lucene query string syntax.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg stored_fields: Comma-separated list of stored fields to\n",
      " |          return.\n",
      " |  \n",
      " |  field_caps(self, body: Any = None, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns the information about the capabilities of fields among multiple\n",
      " |      indices.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: An index filter specified with the Query DSL\n",
      " |      :arg index: Comma-separated list of indices; use `_all` or empty\n",
      " |          string to perform the operation on all indices.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified).\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg fields: Comma-separated list of field names.\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed).\n",
      " |      :arg include_unmapped: Indicates whether unmapped fields should\n",
      " |          be included in the response. Default is false.\n",
      " |  \n",
      " |  get(self, index: Any, id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns a document.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg id: Document ID.\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg realtime: Specify whether to perform the operation in\n",
      " |          realtime or search mode.\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg stored_fields: Comma-separated list of stored fields to\n",
      " |          return.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |  \n",
      " |  get_all_pits(self, params: Any = None, headers: Any = None) -> Any\n",
      " |      Lists all active point in time searches.\n",
      " |  \n",
      " |  get_script(self, id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns a script.\n",
      " |      \n",
      " |      \n",
      " |      :arg id: Script ID.\n",
      " |      :arg cluster_manager_timeout: Operation timeout for connection\n",
      " |          to cluster-manager node.\n",
      " |      :arg master_timeout (Deprecated: To promote inclusive language,\n",
      " |          use 'cluster_manager_timeout' instead.): Operation timeout for\n",
      " |          connection to master node.\n",
      " |  \n",
      " |  get_script_context(self, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns all script contexts.\n",
      " |  \n",
      " |  get_script_languages(self, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns available script types, languages and contexts.\n",
      " |  \n",
      " |  get_source(self, index: Any, id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns the source of a document.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg id: Document ID.\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg realtime: Specify whether to perform the operation in\n",
      " |          realtime or search mode.\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |  \n",
      " |  index(self, index: Any, body: Any, id: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Creates or updates a document in an index.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg body: The document\n",
      " |      :arg id: Document ID.\n",
      " |      :arg if_primary_term: only perform the operation if the last\n",
      " |          operation that has changed the document has the specified primary term.\n",
      " |      :arg if_seq_no: only perform the operation if the last operation\n",
      " |          that has changed the document has the specified sequence number.\n",
      " |      :arg op_type: Explicit operation type. Defaults to `index` for\n",
      " |          requests with an explicit document ID, and to `create` for requests\n",
      " |          without an explicit document ID. Valid choices are index, create.\n",
      " |      :arg pipeline: The pipeline id to preprocess incoming documents\n",
      " |          with.\n",
      " |      :arg refresh: If `true` then refresh the affected shards to make\n",
      " |          this operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default) then\n",
      " |          do nothing with refreshes. Valid choices are true, false, wait_for.\n",
      " |      :arg require_alias: When true, requires destination to be an\n",
      " |          alias. Default is false.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg timeout: Operation timeout.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies\n",
      " |          that must be active before proceeding with the operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the total\n",
      " |          number of copies for the shard (number of replicas + 1). Default is 1.\n",
      " |  \n",
      " |  info(self, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns basic information about the cluster.\n",
      " |  \n",
      " |  list_all_point_in_time(self: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns the list of active point in times searches\n",
      " |      \n",
      " |      .. warning::\n",
      " |      \n",
      " |          This API will be removed in a future version.\n",
      " |          Use 'get_all_pits' API instead.\n",
      " |  \n",
      " |  mget(self, body: Any, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to get multiple documents in one request.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: Document identifiers; can be either `docs`\n",
      " |          (containing full document information) or `ids` (when index is provided\n",
      " |          in the URL.\n",
      " |      :arg index: Index name.\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg realtime: Specify whether to perform the operation in\n",
      " |          realtime or search mode.\n",
      " |      :arg refresh: Refresh the shard containing the document before\n",
      " |          performing the operation.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg stored_fields: Comma-separated list of stored fields to\n",
      " |          return.\n",
      " |  \n",
      " |  msearch(self, body: Any, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to execute several search operations in one request.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The request definitions (metadata-search request\n",
      " |          definition pairs), separated by newlines\n",
      " |      :arg index: Comma-separated list of indices to use as default.\n",
      " |      :arg ccs_minimize_roundtrips: Indicates whether network round-\n",
      " |          trips should be minimized as part of cross-cluster search requests\n",
      " |          execution. Default is True.\n",
      " |      :arg max_concurrent_searches: Controls the maximum number of\n",
      " |          concurrent searches the multi search api will execute.\n",
      " |      :arg max_concurrent_shard_requests: The number of concurrent\n",
      " |          shard requests each sub search executes concurrently per node. This\n",
      " |          value should be used to limit the impact of the search on the cluster in\n",
      " |          order to limit the number of concurrent shard requests. Default is 5.\n",
      " |      :arg pre_filter_shard_size: Threshold that enforces a pre-filter\n",
      " |          round-trip to prefilter search shards based on query rewriting if the\n",
      " |          number of shards the search request expands to exceeds the threshold.\n",
      " |          This filter round-trip can limit the number of shards significantly if\n",
      " |          for instance a shard can not match any documents based on its rewrite\n",
      " |          method ie. if date filters are mandatory to match but the shard bounds\n",
      " |          and the query are disjoint.\n",
      " |      :arg rest_total_hits_as_int: Indicates whether hits.total should\n",
      " |          be rendered as an integer or an object in the rest search response.\n",
      " |          Default is false.\n",
      " |      :arg search_type: Search operation type. Valid choices are\n",
      " |          query_then_fetch, query_and_fetch, dfs_query_then_fetch,\n",
      " |          dfs_query_and_fetch.\n",
      " |      :arg typed_keys: Specify whether aggregation and suggester names\n",
      " |          should be prefixed by their respective types in the response.\n",
      " |  \n",
      " |  msearch_template(self, body: Any, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to execute several search template operations in one request.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The request definitions (metadata-search request\n",
      " |          definition pairs), separated by newlines\n",
      " |      :arg index: Comma-separated list of indices to use as default.\n",
      " |      :arg ccs_minimize_roundtrips: Indicates whether network round-\n",
      " |          trips should be minimized as part of cross-cluster search requests\n",
      " |          execution. Default is True.\n",
      " |      :arg max_concurrent_searches: Controls the maximum number of\n",
      " |          concurrent searches the multi search api will execute.\n",
      " |      :arg rest_total_hits_as_int: Indicates whether hits.total should\n",
      " |          be rendered as an integer or an object in the rest search response.\n",
      " |          Default is false.\n",
      " |      :arg search_type: Search operation type. Valid choices are\n",
      " |          query_then_fetch, query_and_fetch, dfs_query_then_fetch,\n",
      " |          dfs_query_and_fetch.\n",
      " |      :arg typed_keys: Specify whether aggregation and suggester names\n",
      " |          should be prefixed by their respective types in the response.\n",
      " |  \n",
      " |  mtermvectors(self, body: Any = None, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns multiple termvectors in one request.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: Define ids, documents, parameters or a list of\n",
      " |          parameters per document here. You must at least provide a list of\n",
      " |          document ids. See documentation.\n",
      " |      :arg index: The index in which the document resides.\n",
      " |      :arg field_statistics: Specifies if document count, sum of\n",
      " |          document frequencies and sum of total term frequencies should be\n",
      " |          returned. Applies to all returned documents unless otherwise specified\n",
      " |          in body 'params' or 'docs'. Default is True.\n",
      " |      :arg fields: Comma-separated list of fields to return. Applies\n",
      " |          to all returned documents unless otherwise specified in body 'params' or\n",
      " |          'docs'.\n",
      " |      :arg ids: Comma-separated list of documents ids. You must define\n",
      " |          ids as parameter or set 'ids' or 'docs' in the request body.\n",
      " |      :arg offsets: Specifies if term offsets should be returned.\n",
      " |          Applies to all returned documents unless otherwise specified in body\n",
      " |          'params' or 'docs'. Default is True.\n",
      " |      :arg payloads: Specifies if term payloads should be returned.\n",
      " |          Applies to all returned documents unless otherwise specified in body\n",
      " |          'params' or 'docs'. Default is True.\n",
      " |      :arg positions: Specifies if term positions should be returned.\n",
      " |          Applies to all returned documents unless otherwise specified in body\n",
      " |          'params' or 'docs'. Default is True.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Applies to all returned documents unless otherwise\n",
      " |          specified in body 'params' or 'docs'. Default is random.\n",
      " |      :arg realtime: Specifies if requests are real-time as opposed to\n",
      " |          near-real-time. Default is True.\n",
      " |      :arg routing: Routing value. Applies to all returned documents\n",
      " |          unless otherwise specified in body 'params' or 'docs'.\n",
      " |      :arg term_statistics: Specifies if total term frequency and\n",
      " |          document frequency should be returned. Applies to all returned documents\n",
      " |          unless otherwise specified in body 'params' or 'docs'. Default is false.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |  \n",
      " |  ping(self, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns whether the cluster is running.\n",
      " |  \n",
      " |  put_script(self, id: Any, body: Any, context: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Creates or updates a script.\n",
      " |      \n",
      " |      \n",
      " |      :arg id: Script ID.\n",
      " |      :arg body: The document\n",
      " |      :arg context: Script context.\n",
      " |      :arg cluster_manager_timeout: Operation timeout for connection\n",
      " |          to cluster-manager node.\n",
      " |      :arg master_timeout (Deprecated: To promote inclusive language,\n",
      " |          use 'cluster_manager_timeout' instead.): Operation timeout for\n",
      " |          connection to master node.\n",
      " |      :arg timeout: Operation timeout.\n",
      " |  \n",
      " |  rank_eval(self, body: Any, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to evaluate the quality of ranked search results over a set of typical\n",
      " |      search queries.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The ranking evaluation search definition, including\n",
      " |          search requests, document ratings and ranking metric definition.\n",
      " |      :arg index: Comma-separated list of indices; use `_all` or empty\n",
      " |          string to perform the operation on all indices.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified).\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed).\n",
      " |      :arg search_type: Search operation type. Valid choices are\n",
      " |          query_then_fetch, dfs_query_then_fetch.\n",
      " |  \n",
      " |  reindex(self, body: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to copy documents from one index to another, optionally filtering the\n",
      " |      source documents by a query, changing the destination index settings, or\n",
      " |      fetching the documents from a remote cluster.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The search definition using the Query DSL and the\n",
      " |          prototype for the index request.\n",
      " |      :arg max_docs: Maximum number of documents to process (default:\n",
      " |          all documents).\n",
      " |      :arg refresh: Should the affected indexes be refreshed?.\n",
      " |      :arg requests_per_second: The throttle for this request in sub-\n",
      " |          requests per second. -1 means no throttle. Default is 0.\n",
      " |      :arg scroll: Specify how long a consistent view of the index\n",
      " |          should be maintained for scrolled search.\n",
      " |      :arg slices: The number of slices this task should be divided\n",
      " |          into. Defaults to 1, meaning the task isn't sliced into subtasks. Can be\n",
      " |          set to `auto`. Default is 1.\n",
      " |      :arg timeout: Time each individual bulk request should wait for\n",
      " |          shards that are unavailable. Default is 1m.\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies\n",
      " |          that must be active before proceeding with the operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the total\n",
      " |          number of copies for the shard (number of replicas + 1). Default is 1.\n",
      " |      :arg wait_for_completion: Should this request wait until the\n",
      " |          operation has completed before returning. Default is True.\n",
      " |  \n",
      " |  reindex_rethrottle(self, task_id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Changes the number of requests per second for a particular Reindex operation.\n",
      " |      \n",
      " |      \n",
      " |      :arg task_id: The task id to rethrottle.\n",
      " |      :arg requests_per_second: The throttle for this request in sub-\n",
      " |          requests per second. -1 means no throttle.\n",
      " |  \n",
      " |  render_search_template(self, body: Any = None, id: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to use the Mustache language to pre-render a search definition.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The search definition template and its params\n",
      " |      :arg id: The id of the stored search template.\n",
      " |  \n",
      " |  scripts_painless_execute(self, body: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows an arbitrary script to be executed and a result to be returned.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The script to execute\n",
      " |  \n",
      " |  scroll(self, body: Any = None, scroll_id: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to retrieve a large numbers of results from a single search request.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The scroll ID if not passed by URL or query\n",
      " |          parameter.\n",
      " |      :arg scroll_id: Scroll ID.\n",
      " |      :arg rest_total_hits_as_int: Indicates whether hits.total should\n",
      " |          be rendered as an integer or an object in the rest search response.\n",
      " |          Default is false.\n",
      " |      :arg scroll: Specify how long a consistent view of the index\n",
      " |          should be maintained for scrolled search.\n",
      " |  \n",
      " |  search(self, body: Any = None, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns results matching a query.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The search definition using the Query DSL\n",
      " |      :arg index: Comma-separated list of indices; use `_all` or empty\n",
      " |          string to perform the operation on all indices.\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified).\n",
      " |      :arg allow_partial_search_results: Indicate if an error should\n",
      " |          be returned if there is a partial search failure or timeout. Default is\n",
      " |          True.\n",
      " |      :arg analyze_wildcard: Specify whether wildcard and prefix\n",
      " |          queries should be analyzed. Default is false.\n",
      " |      :arg analyzer: The analyzer to use for the query string.\n",
      " |      :arg batched_reduce_size: The number of shard results that\n",
      " |          should be reduced at once on the coordinating node. This value should be\n",
      " |          used as a protection mechanism to reduce the memory overhead per search\n",
      " |          request if the potential number of shards in the request can be large.\n",
      " |          Default is 512.\n",
      " |      :arg ccs_minimize_roundtrips: Indicates whether network round-\n",
      " |          trips should be minimized as part of cross-cluster search requests\n",
      " |          execution. Default is True.\n",
      " |      :arg default_operator: The default operator for query string\n",
      " |          query (AND or OR). Valid choices are AND, OR.\n",
      " |      :arg df: The field to use as default where no field prefix is\n",
      " |          given in the query string.\n",
      " |      :arg docvalue_fields: Comma-separated list of fields to return\n",
      " |          as the docvalue representation of a field for each hit.\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg explain: Specify whether to return detailed information\n",
      " |          about score computation as part of a hit.\n",
      " |      :arg from_: Starting offset. Default is 0.\n",
      " |      :arg ignore_throttled: Whether specified concrete, expanded or\n",
      " |          aliased indices should be ignored when throttled.\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed).\n",
      " |      :arg lenient: Specify whether format-based query failures (such\n",
      " |          as providing text to a numeric field) should be ignored.\n",
      " |      :arg max_concurrent_shard_requests: The number of concurrent\n",
      " |          shard requests per node this search executes concurrently. This value\n",
      " |          should be used to limit the impact of the search on the cluster in order\n",
      " |          to limit the number of concurrent shard requests. Default is 5.\n",
      " |      :arg pre_filter_shard_size: Threshold that enforces a pre-filter\n",
      " |          round-trip to prefilter search shards based on query rewriting if the\n",
      " |          number of shards the search request expands to exceeds the threshold.\n",
      " |          This filter round-trip can limit the number of shards significantly if\n",
      " |          for instance a shard can not match any documents based on its rewrite\n",
      " |          method ie. if date filters are mandatory to match but the shard bounds\n",
      " |          and the query are disjoint.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg q: Query in the Lucene query string syntax.\n",
      " |      :arg request_cache: Specify if request cache should be used for\n",
      " |          this request or not, defaults to index level setting.\n",
      " |      :arg rest_total_hits_as_int: Indicates whether hits.total should\n",
      " |          be rendered as an integer or an object in the rest search response.\n",
      " |          Default is false.\n",
      " |      :arg routing: Comma-separated list of specific routing values.\n",
      " |      :arg scroll: Specify how long a consistent view of the index\n",
      " |          should be maintained for scrolled search.\n",
      " |      :arg search_type: Search operation type. Valid choices are\n",
      " |          query_then_fetch, dfs_query_then_fetch.\n",
      " |      :arg seq_no_primary_term: Specify whether to return sequence\n",
      " |          number and primary term of the last modification of each hit.\n",
      " |      :arg size: Number of hits to return. Default is 10.\n",
      " |      :arg sort: Comma-separated list of <field>:<direction> pairs.\n",
      " |      :arg stats: Specific 'tag' of the request for logging and\n",
      " |          statistical purposes.\n",
      " |      :arg stored_fields: Comma-separated list of stored fields to\n",
      " |          return.\n",
      " |      :arg suggest_field: Specify which field to use for suggestions.\n",
      " |      :arg suggest_mode: Specify suggest mode. Valid choices are\n",
      " |          missing, popular, always.\n",
      " |      :arg suggest_size: How many suggestions to return in response.\n",
      " |      :arg suggest_text: The source text for which the suggestions\n",
      " |          should be returned.\n",
      " |      :arg terminate_after: The maximum number of documents to collect\n",
      " |          for each shard, upon reaching which the query execution will terminate\n",
      " |          early.\n",
      " |      :arg timeout: Operation timeout.\n",
      " |      :arg track_scores: Whether to calculate and return scores even\n",
      " |          if they are not used for sorting.\n",
      " |      :arg track_total_hits: Indicate if the number of documents that\n",
      " |          match the query should be tracked.\n",
      " |      :arg typed_keys: Specify whether aggregation and suggester names\n",
      " |          should be prefixed by their respective types in the response.\n",
      " |      :arg version: Whether to return document version as part of a\n",
      " |          hit.\n",
      " |  \n",
      " |  search_shards(self, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns information about the indices and shards that a search request would be\n",
      " |      executed against.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Comma-separated list of indices; use `_all` or empty\n",
      " |          string to perform the operation on all indices.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified).\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed).\n",
      " |      :arg local: Return local information, do not retrieve the state\n",
      " |          from cluster-manager node. Default is false.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg routing: Routing value.\n",
      " |  \n",
      " |  search_template(self, body: Any, index: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Allows to use the Mustache language to pre-render a search definition.\n",
      " |      \n",
      " |      \n",
      " |      :arg body: The search definition template and its params\n",
      " |      :arg index: Comma-separated list of indices; use `_all` or empty\n",
      " |          string to perform the operation on all indices.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified).\n",
      " |      :arg ccs_minimize_roundtrips: Indicates whether network round-\n",
      " |          trips should be minimized as part of cross-cluster search requests\n",
      " |          execution. Default is True.\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg explain: Specify whether to return detailed information\n",
      " |          about score computation as part of a hit.\n",
      " |      :arg ignore_throttled: Whether specified concrete, expanded or\n",
      " |          aliased indices should be ignored when throttled.\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed).\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg profile: Specify whether to profile the query execution.\n",
      " |      :arg rest_total_hits_as_int: Indicates whether hits.total should\n",
      " |          be rendered as an integer or an object in the rest search response.\n",
      " |          Default is false.\n",
      " |      :arg routing: Comma-separated list of specific routing values.\n",
      " |      :arg scroll: Specify how long a consistent view of the index\n",
      " |          should be maintained for scrolled search.\n",
      " |      :arg search_type: Search operation type. Valid choices are\n",
      " |          query_then_fetch, query_and_fetch, dfs_query_then_fetch,\n",
      " |          dfs_query_and_fetch.\n",
      " |      :arg typed_keys: Specify whether aggregation and suggester names\n",
      " |          should be prefixed by their respective types in the response.\n",
      " |  \n",
      " |  termvectors(self, index: Any, body: Any = None, id: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Returns information and statistics about terms in the fields of a particular\n",
      " |      document.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: The index in which the document resides.\n",
      " |      :arg body: Define parameters and or supply a document to get\n",
      " |          termvectors for. See documentation.\n",
      " |      :arg id: Document ID. When not specified a doc param should be\n",
      " |          supplied.\n",
      " |      :arg field_statistics: Specifies if document count, sum of\n",
      " |          document frequencies and sum of total term frequencies should be\n",
      " |          returned. Default is True.\n",
      " |      :arg fields: Comma-separated list of fields to return.\n",
      " |      :arg offsets: Specifies if term offsets should be returned.\n",
      " |          Default is True.\n",
      " |      :arg payloads: Specifies if term payloads should be returned.\n",
      " |          Default is True.\n",
      " |      :arg positions: Specifies if term positions should be returned.\n",
      " |          Default is True.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg realtime: Specifies if request is real-time as opposed to\n",
      " |          near-real-time. Default is True.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg term_statistics: Specifies if total term frequency and\n",
      " |          document frequency should be returned. Default is false.\n",
      " |      :arg version: Explicit version number for concurrency control.\n",
      " |      :arg version_type: Specific version type. Valid choices are\n",
      " |          internal, external, external_gte, force.\n",
      " |  \n",
      " |  update(self, index: Any, id: Any, body: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Updates a document with a script or partial document.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Index name.\n",
      " |      :arg id: Document ID.\n",
      " |      :arg body: The request definition requires either `script` or\n",
      " |          partial `doc`\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg if_primary_term: only perform the operation if the last\n",
      " |          operation that has changed the document has the specified primary term.\n",
      " |      :arg if_seq_no: only perform the operation if the last operation\n",
      " |          that has changed the document has the specified sequence number.\n",
      " |      :arg lang: The script language. Default is painless.\n",
      " |      :arg refresh: If `true` then refresh the affected shards to make\n",
      " |          this operation visible to search, if `wait_for` then wait for a refresh\n",
      " |          to make this operation visible to search, if `false` (the default) then\n",
      " |          do nothing with refreshes. Valid choices are true, false, wait_for.\n",
      " |      :arg require_alias: When true, requires destination to be an\n",
      " |          alias. Default is false.\n",
      " |      :arg retry_on_conflict: Specify how many times should the\n",
      " |          operation be retried when a conflict occurs. Default is 0.\n",
      " |      :arg routing: Routing value.\n",
      " |      :arg timeout: Operation timeout.\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies\n",
      " |          that must be active before proceeding with the operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the total\n",
      " |          number of copies for the shard (number of replicas + 1). Default is 1.\n",
      " |  \n",
      " |  update_by_query(self, index: Any, body: Any = None, params: Any = None, headers: Any = None) -> Any\n",
      " |      Performs an update on every document in the index without changing the source,\n",
      " |      for example to pick up a mapping change.\n",
      " |      \n",
      " |      \n",
      " |      :arg index: Comma-separated list of indices; use `_all` or empty\n",
      " |          string to perform the operation on all indices.\n",
      " |      :arg body: The search definition using the Query DSL\n",
      " |      :arg _source: True or false to return the _source field or not,\n",
      " |          or a list of fields to return.\n",
      " |      :arg _source_excludes: List of fields to exclude from the\n",
      " |          returned _source field.\n",
      " |      :arg _source_includes: List of fields to extract and return from\n",
      " |          the _source field.\n",
      " |      :arg allow_no_indices: Whether to ignore if a wildcard indices\n",
      " |          expression resolves into no concrete indices. (This includes `_all`\n",
      " |          string or when no indices have been specified).\n",
      " |      :arg analyze_wildcard: Specify whether wildcard and prefix\n",
      " |          queries should be analyzed. Default is false.\n",
      " |      :arg analyzer: The analyzer to use for the query string.\n",
      " |      :arg conflicts: What to do when the operation encounters version\n",
      " |          conflicts?. Valid choices are abort, proceed.\n",
      " |      :arg default_operator: The default operator for query string\n",
      " |          query (AND or OR). Valid choices are AND, OR.\n",
      " |      :arg df: The field to use as default where no field prefix is\n",
      " |          given in the query string.\n",
      " |      :arg expand_wildcards: Whether to expand wildcard expression to\n",
      " |          concrete indices that are open, closed or both. Valid choices are all,\n",
      " |          open, closed, hidden, none.\n",
      " |      :arg from_: Starting offset. Default is 0.\n",
      " |      :arg ignore_unavailable: Whether specified concrete indices\n",
      " |          should be ignored when unavailable (missing or closed).\n",
      " |      :arg lenient: Specify whether format-based query failures (such\n",
      " |          as providing text to a numeric field) should be ignored.\n",
      " |      :arg max_docs: Maximum number of documents to process (default:\n",
      " |          all documents).\n",
      " |      :arg pipeline: The pipeline id to preprocess incoming documents\n",
      " |          with.\n",
      " |      :arg preference: Specify the node or shard the operation should\n",
      " |          be performed on. Default is random.\n",
      " |      :arg q: Query in the Lucene query string syntax.\n",
      " |      :arg refresh: Should the affected indexes be refreshed?.\n",
      " |      :arg request_cache: Specify if request cache should be used for\n",
      " |          this request or not, defaults to index level setting.\n",
      " |      :arg requests_per_second: The throttle for this request in sub-\n",
      " |          requests per second. -1 means no throttle. Default is 0.\n",
      " |      :arg routing: Comma-separated list of specific routing values.\n",
      " |      :arg scroll: Specify how long a consistent view of the index\n",
      " |          should be maintained for scrolled search.\n",
      " |      :arg scroll_size: Size on the scroll request powering the\n",
      " |          operation. Default is 100.\n",
      " |      :arg search_timeout: Explicit timeout for each search request.\n",
      " |          Defaults to no timeout.\n",
      " |      :arg search_type: Search operation type. Valid choices are\n",
      " |          query_then_fetch, dfs_query_then_fetch.\n",
      " |      :arg size: Deprecated, please use `max_docs` instead.\n",
      " |      :arg slices: The number of slices this task should be divided\n",
      " |          into. Defaults to 1, meaning the task isn't sliced into subtasks. Can be\n",
      " |          set to `auto`. Default is 1.\n",
      " |      :arg sort: Comma-separated list of <field>:<direction> pairs.\n",
      " |      :arg stats: Specific 'tag' of the request for logging and\n",
      " |          statistical purposes.\n",
      " |      :arg terminate_after: The maximum number of documents to collect\n",
      " |          for each shard, upon reaching which the query execution will terminate\n",
      " |          early.\n",
      " |      :arg timeout: Time each individual bulk request should wait for\n",
      " |          shards that are unavailable. Default is 1m.\n",
      " |      :arg version: Whether to return document version as part of a\n",
      " |          hit.\n",
      " |      :arg wait_for_active_shards: Sets the number of shard copies\n",
      " |          that must be active before proceeding with the operation. Defaults to 1,\n",
      " |          meaning the primary shard only. Set to `all` for all shard copies,\n",
      " |          otherwise set to any non-negative value less than or equal to the total\n",
      " |          number of copies for the shard (number of replicas + 1). Default is 1.\n",
      " |      :arg wait_for_completion: Should this request wait until the\n",
      " |          operation has completed before returning. Default is True.\n",
      " |  \n",
      " |  update_by_query_rethrottle(self, task_id: Any, params: Any = None, headers: Any = None) -> Any\n",
      " |      Changes the number of requests per second for a particular Update By Query\n",
      " |      operation.\n",
      " |      \n",
      " |      \n",
      " |      :arg task_id: The task id to rethrottle.\n",
      " |      :arg requests_per_second: The throttle for this request in sub-\n",
      " |          requests per second. -1 means no throttle.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from opensearchpy.client.client.Client:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(client)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
